{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c96892-04b1-407b-bc4c-e7d1c984db19",
   "metadata": {},
   "source": [
    "## Example of how to run detections using the original EQTransformer trained model\n",
    "Resource used: https://eqtransformer.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986d496-5d57-4b25-852e-900be439ea3f",
   "metadata": {},
   "source": [
    "# Environment/repository set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f23398-8524-41d0-95d5-d70d31a76463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import glob2 as glob\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29743a-2ee8-4207-8c1d-7e259ad421bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and set-up EQTransformer following installation via git\n",
    "\n",
    "# NOTE: if using Google CoLab, make sure the runtime includes GPU before starting\n",
    "!pip install git+https://github.com/smousavi05/EQTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9467706-8af0-4dc3-a79c-95b94518002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone in the repository setup- this is what contains the pre-trained model, so this is necessary\n",
    "\n",
    "!git clone https://github.com/UW-ESS-DS/krauss-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cf755-02f8-4284-953d-8fb5015aebf3",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab2c1e-2869-481f-8990-9f2716383147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station list needs to be in json format- here's an example of how one is made\n",
    "\n",
    "# Make list of stations to query\n",
    "\n",
    "from EQTransformer.utils.downloader import makeStationList\n",
    "\n",
    "# For all stations:\n",
    "makeStationList('stationlist.json',client_list=[\"IRIS\"],min_lat =47.5 , max_lat = 48.5,min_lon=-129.4,max_lon=-128.8,start_time='2018-08-03T00:00:00',end_time='2018-08-05T00:00:00',channel_list=['HH[ZNE]','EH[ZNE]', 'HH[Z21]','EH[Z21]', 'CH[ZNE]'],filter_network=['SY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565b7be-7541-4960-b00e-d83f42a068f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download mseeds for desired time period - this function stores them in a specific folder/file tree format that is needed for the other EQT commands\n",
    "from EQTransformer.utils.downloader import downloadMseeds\n",
    "\n",
    "stime = \"2018-08-01 00:00:00.00\"\n",
    "ftime = \"2018-08-05 00:00:00.00\"\n",
    "\n",
    "downloadMseeds(client_list=[\"IRIS\"], stations_json='stationlist.json', output_dir=\"downloads_mseeds_august3_2018\",min_lat =47.5 , max_lat = 48.5,min_lon=-129.4,max_lon=-128.8,start_time=stime,end_time=ftime, chunk_size=1, channel_list=[\"HH[ZNE]\",\"EH[ZNE]\", \"HH[Z21]\",\"EH[Z21]\", \"CH[ZNE]\"], n_processor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b02d7e-6642-4d2a-83df-bbd8e1448d23",
   "metadata": {},
   "source": [
    "# Perform detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f42eb-2e36-426c-a4d8-8247f999b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.core.mseed_predictor import mseed_predictor\n",
    "    \n",
    "mseed_predictor(input_dir='/home/zkrauss/scratch/krauss-repo/downloads_mseeds',   \n",
    "                    input_model='/home/zkrauss/scratch/krauss-repo/eq_project/eqtransformer_local/ModelsAndSampleData/EqT_model.h5',\n",
    "                    stations_json='end_stationlist.json',\n",
    "                    output_dir='/home/zkrauss/scratch/krauss-repo/end_test1',\n",
    "                    detection_threshold=0.2,                \n",
    "                    P_threshold=0.1,\n",
    "                    S_threshold=0.1,  \n",
    "                    number_of_plots=0,\n",
    "                    batch_size=20,\n",
    "                    overlap=0.3,\n",
    "                    output_probabilities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fed046-a68e-47a0-9bd5-5b2b90faf32a",
   "metadata": {},
   "source": [
    "# Look at results- both picks and probability streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7013a-73c1-4a63-a8e9-450c5aeb74d1",
   "metadata": {},
   "source": [
    "## Detections and picks are stored in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd05b1-48eb-491a-8e32-8149f5905f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can gather them into a pandas dataframe as follows, just change your base directory\n",
    "base_dir = '/home/zkrauss/alaska-continuous/krauss-repo/aacse_detection_all/'\n",
    "res_files = glob.glob(base_dir + '**/X*results.csv')\n",
    "eqt_picks = pd.concat([pd.read_csv(f) for f in res_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf00e41-208d-4643-8603-50aa72f7d646",
   "metadata": {},
   "source": [
    "## Probability streams are stored in h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e38df9-e325-4782-b019-dcbedc6bcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# To get a list of earthquakes found for a specific station, you can do as follows for a given station file\n",
    "filename='/home/zkrauss/alaska-continuous/krauss-repo/aacse_detection_forfigs/EP22_outputs/prediction_probabilities.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "list(f.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d88b2-481d-4de0-bba0-d29aabfdbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then pick out an earthquake from the list and you can get the detection, P, and S probability vectors as follows\n",
    "\n",
    "dset = f['2019-05-27 03:15:18.009998']\n",
    "d_prob = dset['Earthquake'][:]\n",
    "p_prob = dset['P_arrival'][:]\n",
    "s_prob = dset['S_arrival'][:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alaska-ml",
   "language": "python",
   "name": "alaska-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
