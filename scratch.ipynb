{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b6824b-1adf-4989-98a0-f2625cee4abe",
   "metadata": {},
   "source": [
    "## All choices made here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039687f3-d8be-4259-b31e-ce4d874ee9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_length = 60\n",
    "waveform_overlap = 20\n",
    "starttime = datetime.datetime(2018,5,25,12,35)\n",
    "endtime = datetime.datetime(2018,5,25,12,38)\n",
    "\n",
    "\n",
    "# FILTER TYPES:\n",
    "# 0 for raw waveforms\n",
    "# 1 for DeepDenoiser\n",
    "# 2 for bandpass filter**\n",
    "# ** if specifying bandpass filter, must also specify f1 and f2 for bandpass limits\n",
    "filt_type = 0\n",
    "f1 = False\n",
    "f2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf16714-5f0a-4a32-9047-82eeb457366a",
   "metadata": {},
   "source": [
    "## Command to run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0a0692-a257-4e87-a4b9-1b84c78689d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_pick' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_picks,output_gamma \u001b[38;5;241m=\u001b[39m \u001b[43mml_pick\u001b[49m(starttime,endtime,waveform_length,waveform_overlap,filt_type,f1,f2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_pick' is not defined"
     ]
    }
   ],
   "source": [
    "output_picks,output_gamma = ml_pick(starttime,endtime,waveform_length,waveform_overlap,filt_type,f1,f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0126d62-65a3-42ff-bd23-9e2b9d12e661",
   "metadata": {},
   "source": [
    "## Workflow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a52f0-063c-4623-9489-2999d0681ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pick(t1,t2,waveform_length,waveform_overlap,filt_type,f1=False,f2=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load master station list\n",
    "    dfS = pd.read_parquet('https://github.com/zoekrauss/alaska_catalog/raw/main/data_acquisition/alaska_stations.parquet')\n",
    "    # Convert to pandas datetime\n",
    "    dfS['start_date']=pd.to_datetime(dfS['start_date'],infer_datetime_format=True,errors='coerce')\n",
    "    dfS['end_date']=pd.to_datetime(dfS['end_date'],infer_datetime_format=True,errors='coerce')\n",
    "\n",
    "    # Download waveforms\n",
    "    time_bins = pd.to_datetime(np.arange(t1,t2,pd.Timedelta(waveform_length-waveform_overlap,'seconds')))\n",
    "    @dask.delayed\n",
    "    def loop_times(dfS,t1,waveform_length):\n",
    "        return alaska_utils.retrieve_waveforms(dfS,t1,t1+pd.Timedelta(waveform_length,'seconds'),separate=True)\n",
    "\n",
    "    lazy_results = [loop_times(dfS,time,waveform_length) for time in time_bins]\n",
    "    \n",
    "    results = dask.compute(lazy_results)\n",
    "    # Concat into big list of streams\n",
    "    test = sum(results,[]); stream = []\n",
    "    for t in test:\n",
    "        stream.extend(t)\n",
    "    \n",
    "    # Filter waveforms as specified, then apply EQTransformer\n",
    "    if filt_type==0:\n",
    "        annotate = apply_eqt(stream)\n",
    "         pick_info = get_picks(stream,annotate,filtered=False,filt_type=filt_type)\n",
    "    if filt_type==1:\n",
    "        filtered = filter_waveforms(stream,f1,f2)\n",
    "        annotate = apply_eqt(filtered)\n",
    "        pick_info = get_picks(stream,annotate,filtered=filtered,filt_type=filt_type)\n",
    "    if filt_type==2:\n",
    "        denoised = denoise_waveforms(stream)\n",
    "        annotate = apply_eqt(denoised)\n",
    "        pick_info = get_picks(stream,annotate,filtered=denoised,filt_type=filt_type)\n",
    "        \n",
    "    gamma_picks = convert_to_gamma(pick_info)  \n",
    "    \n",
    "    return pick_info,gamma_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ef74e-eff3-498c-bbff-903125098417",
   "metadata": {
    "tags": []
   },
   "source": [
    "## If specified, denoise the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abf9b4-d73f-4050-ba55-4de86732aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_waveforms(stream):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = sbm.DeepDenoiser.from_pretrained(\"original\")\n",
    "    \n",
    "    # Apply DeepDenoiser model\n",
    "    denoise = np.empty([len(stream)],dtype=object)\n",
    "    for i,st in enumerate(stream):\n",
    "        den = model.annotate(st)\n",
    "        denoise[i]=den\n",
    "    \n",
    "    return denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d0508-5ac6-4226-be48-4351cf02c619",
   "metadata": {},
   "source": [
    "## If specified, filter the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c9e96-bcdd-4649-9413-ddc13506ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_waveforms(stream,f1,f2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    stream.filter('bandpass',freqmin=f1,freqmax=f2)\n",
    "    \n",
    "    return stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a935d-9728-420b-859a-816cbeefbfc4",
   "metadata": {},
   "source": [
    "## Apply EQTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627ec19-6ff0-4a78-beda-dd0638374447",
   "metadata": {},
   "outputs": [],
   "source": [
    " def apply_eqt(stream):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = sbm.EQTransformer.from_pretrained(\"original\")\n",
    "    # EDIT MODEL TO NOT CUT SAMPLES OFF \n",
    "    model.default_args[\"blinding\"] = (0,0)\n",
    "\n",
    "    annotation = np.empty([len(stream)],dtype=object)\n",
    "    for i,st in enumerate(stream):\n",
    "        at = model.annotate(st)\n",
    "        annotation[i]=at; \n",
    "\n",
    "    return annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1043d0-10a2-4594-8e88-b1532332bd6a",
   "metadata": {},
   "source": [
    "## Save results as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b602123-3cac-4646-a0df-26e9833b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_picks(stream,annotate,denoise=False,filt_type):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pick_meta=[];\n",
    "    for i in range(int(len(annotation))):\n",
    "\n",
    "        # For empty annotations:\n",
    "        if not annotation[i]:\n",
    "            continue\n",
    "\n",
    "        preds = np.empty([1,annotation[i][0].stats.npts,1,3])\n",
    "        preds[0,:,0,0] = annotation[i][0].data\n",
    "        preds[0,:,0,1] = annotation[i][1].data\n",
    "        preds[0,:,0,2] = annotation[i][2].data\n",
    "\n",
    "        station_id = annotation[i][0].stats.network + '..' + annotation[i][0].stats.station + '.'\n",
    "        final_id = stream[i][0].stats.network + '.' + stream[i][0].stats.station + '..' + stream[i][0].stats.channel[0:2]\n",
    "\n",
    "        picks = postprocess.extract_picks(preds,station_ids = [station_id],fnames = [station_id],t0=[str(annotation[i][0].stats.starttime)])\n",
    "\n",
    "        # now call to original data using the same i index to get amplitudes\n",
    "\n",
    "        # Raw amplitudes\n",
    "        raw = np.empty([1,stream[i][0].stats.npts,1,3])\n",
    "        raw[0,:,0,0] = stream[i].select(channel=\"**Z\")[0].data[0:6000]\n",
    "        if stream[i].select(channel=\"**N\"):\n",
    "            raw[0,:,0,1] = stream[i].select(channel=\"**N\")[0].data[0:6000]\n",
    "            raw[0,:,0,2] = stream[i].select(channel=\"**E\")[0].data[0:6000]\n",
    "        else:\n",
    "            raw[0,:,0,1] = stream[i].select(channel=\"**1\")[0].data[0:6000]\n",
    "            raw[0,:,0,2] = stream[i].select(channel=\"**2\")[0].data[0:6000]\n",
    "        raw_amps = postprocess.extract_amplitude(raw,picks)\n",
    "\n",
    "        # Denoised amplitudes\n",
    "        if filt_type:\n",
    "            dat = np.empty([1,denoise[i][0].stats.npts,1,3])\n",
    "            dat[0,:,0,0] = denoise[i].select(channel=\"**Z\")[0].data[0:6000]\n",
    "            if stream[i].select(channel=\"**N\"):\n",
    "                dat[0,:,0,1] = denoise[i].select(channel=\"**N\")[0].data[0:6000]\n",
    "                dat[0,:,0,2] = denoise[i].select(channel=\"**E\")[0].data[0:6000]\n",
    "            else:\n",
    "                dat[0,:,0,1] = denoise[i].select(channel=\"**1\")[0].data[0:6000]\n",
    "                dat[0,:,0,2] = denoise[i].select(channel=\"**2\")[0].data[0:6000]\n",
    "            den_amps = postprocess.extract_amplitude(dat,picks)\n",
    "\n",
    "        # Then, if the pick isn't empty, calculate SNR of pick\n",
    "        if picks[0].p_prob[0]:\n",
    "            for j in range(len(picks[0].p_prob[0])):\n",
    "                # Get timestamp of pick:\n",
    "                ts = annotation[i][0].stats.starttime + (pd.Timedelta(1,'seconds')*annotation[i][0].stats.delta*picks[0].p_idx[0][j])\n",
    "                # Get SNR of pick:\n",
    "                z_raw_snr = calc_snr(stream[i].select(channel=\"**Z\")[0],picks[0].p_idx[0][j],'P');\n",
    "                if filt_type:\n",
    "                    z_den_snr = calc_snr(denoise[i].select(channel=\"**Z\")[0],picks[0].p_idx[0][j],'P');\n",
    "                if stream[i].select(channel=\"**N\"):\n",
    "                    n_raw_snr = calc_snr(stream[i].select(channel=\"**N\")[0],picks[0].p_idx[0][j],'P');\n",
    "                    e_raw_snr = calc_snr(stream[i].select(channel=\"**E\")[0],picks[0].p_idx[0][j],'P');\n",
    "                    if filt_type:\n",
    "                        n_den_snr = calc_snr(denoise[i].select(channel=\"**N\")[0],picks[0].p_idx[0][j],'P');\n",
    "                        e_den_snr = calc_snr(denoise[i].select(channel=\"**E\")[0],picks[0].p_idx[0][j],'P');\n",
    "                else:\n",
    "                    n_raw_snr = calc_snr(stream[i].select(channel=\"**1\")[0],picks[0].p_idx[0][j],'P');\n",
    "                    e_raw_snr = calc_snr(stream[i].select(channel=\"**2\")[0],picks[0].p_idx[0][j],'P');\n",
    "                    if filt_type:\n",
    "                        n_den_snr = calc_snr(denoise[i].select(channel=\"**1\")[0],picks[0].p_idx[0][j],'P');\n",
    "                        e_den_snr = calc_snr(denoise[i].select(channel=\"**2\")[0],picks[0].p_idx[0][j],'P');\n",
    "                if ~filt_type:\n",
    "                    z_den_snr = NaN; n_den_snr = NaN; e_den_snr = NaN;\n",
    "                    den_amp=NaN\n",
    "                else:\n",
    "                    den_amp = den_amps[0].p_amp[0][j]\n",
    "                # Save all info in dictionary:\n",
    "                p_dict = {'id':final_id,'network':stream[i][0].stats.network,'station':stream[i][0].stats.station,'channel':stream[i][0].stats.channel[0:2],'phase':'P',\\\n",
    "                          'timestamp':ts,'prob':picks[0].p_prob[0][j],'raw_amp':raw_amps[0].p_amp[0][j],'den_amp':den_amp,\\\n",
    "                          'z_raw_snr':z_raw_snr,'z_den_snr':z_den_snr,'n_raw_snr':n_raw_snr,'n_den_snr':n_den_snr,'e_raw_snr':e_raw_snr,'e_den_snr':e_den_snr}\n",
    "                pick_meta.append(p_dict)\n",
    "        if picks[0].s_prob[0]:\n",
    "            for j in range(len(picks[0].s_prob[0])):\n",
    "                # Get timestamp of pick:\n",
    "                ts = annotation[i][0].stats.starttime + (pd.Timedelta(1,'seconds')*annotation[i][0].stats.delta*picks[0].s_idx[0][j])\n",
    "                # Get SNR of pick:\n",
    "                z_raw_snr = calc_snr(stream[i].select(channel=\"**Z\")[0],picks[0].s_idx[0][j],'S');\n",
    "                if filt_type:\n",
    "                    z_den_snr = calc_snr(denoise[i].select(channel=\"**Z\")[0],picks[0].s_idx[0][j],'S');\n",
    "                if stream[i].select(channel=\"**N\"):\n",
    "                    n_raw_snr = calc_snr(stream[i].select(channel=\"**N\")[0],picks[0].s_idx[0][j],'S');\n",
    "                    e_raw_snr = calc_snr(stream[i].select(channel=\"**E\")[0],picks[0].s_idx[0][j],'S');\n",
    "                    if filt_type:\n",
    "                        n_den_snr = calc_snr(denoise[i].select(channel=\"**N\")[0],picks[0].s_idx[0][j],'S');\n",
    "                        e_den_snr = calc_snr(denoise[i].select(channel=\"**E\")[0],picks[0].s_idx[0][j],'S');\n",
    "                else:\n",
    "                    n_raw_snr = calc_snr(stream[i].select(channel=\"**1\")[0],picks[0].s_idx[0][j],'S');\n",
    "                    e_raw_snr = calc_snr(stream[i].select(channel=\"**2\")[0],picks[0].s_idx[0][j],'S');\n",
    "                    if filt_type:\n",
    "                        n_den_snr = calc_snr(denoise[i].select(channel=\"**1\")[0],picks[0].s_idx[0][j],'S');\n",
    "                        e_den_snr = calc_snr(denoise[i].select(channel=\"**2\")[0],picks[0].s_idx[0][j],'S');\n",
    "                if ~filt_type:\n",
    "                    z_den_snr = NaN; n_den_snr = NaN; e_den_snr = NaN;\n",
    "                    den_amp=NaN\n",
    "                else:\n",
    "                    den_amp = den_amps[0].s_amp[0][j]\n",
    "                # Save all info in dictionary:\n",
    "                s_dict = {'id':final_id,'network':stream[i][0].stats.network,'station':stream[i][0].stats.station,'channel':stream[i][0].stats.channel[0:2],'phase':'S',\\\n",
    "                          'timestamp':ts,'prob':picks[0].s_prob[0][j],'raw_amp':raw_amps[0].s_amp[0][j],'den_amp':den_amp,\\\n",
    "                          'z_raw_snr':z_raw_snr,'z_den_snr':z_den_snr,'n_raw_snr':n_raw_snr,'n_den_snr':n_den_snr,'e_raw_snr':e_raw_snr,'e_den_snr':e_den_snr}\n",
    "                pick_meta.append(s_dict)\n",
    "\n",
    "    # Save all pick info as pandas dataframe\n",
    "    pick_info = pd.DataFrame.from_dict(pick_meta)\n",
    "    \n",
    "    return(pick_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
